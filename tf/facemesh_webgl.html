<!DOCTYPE html>
<html>
<head>
    <meta charset='utf-8'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <title>Page Title</title>
  
    <!-- Import @tensorflow/tfjs or @tensorflow/tfjs-core -->


<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh"></script>

<!-- Adds the WASM backend to the global backend registry -->
<script  src="https://zoqol.github.io/minimalcomps.min.js"></script>
<style>
    	#camera{
		max-width: 100vw;
		height: auto;
    border: 1px solid gray;
	}
  #rect{
    border: 1px solid red;
    width: 0px;
    height: 0px;
    position: absolute;
  }
  body{
    background-color: #eee;
    margin: 0;
    display: flex;
    justify-content: center;
    align-items: center;
    height: 100vh;
    width: 100vw;
    overflow: hidden;
  }
  .container{
    position: relative;
    display: inline-block;
  }

  #logs{
    position: fixed;
    width: 200px;
    height: 100vh;
    background-color: rgba(0,0,0,.5);
    left: 0;
    top: 0;
    z-index: 3;
    color: white;
    overflow: scroll;
  }
</style>
</head>
<body>

    <div id="logs">

    </div>
         <div class="container">
        <video autoPlay id="camera" ></video>
        <div id="rect">
    
        </div>
    
       </div>

    <script>
       // tf.setBackend('wasm').then(() => main());
       main()
        function main(){
            
            
const DEBUGMODE=true;
function trace(x) {
	if(DEBUGMODE) console.log(x)

	// body...
}

const modelConfig = {  scale: 0.7 };



 const loadModel = () => {
    const promise = new Promise((resolve, reject) => {

      facemesh.load(modelConfig).then(network => {
        resolve(network);

      }).catch(x => {
        reject(x);
      });

    })

    return promise;
  };

var video=document.querySelector('#camera');
var rect=document.querySelector('#rect');
var logs=document.querySelector('#logs');
var requestDelay=200;
const THRESHOLD = 34;
 

const { Checkbox,Panel,HSlider, Button, Canvas, HBox, Toggle,TextArea, Defaults, Dropdown, Label,Window } = mc2;


const panel = new Window(document.body, "Control", 250, 20, 200, 400);
let showRect=true;

new HSlider(panel, 10, 35, "request delay:", 20, 0, 100,(evt)=>{
	requestDelay=1000*evt.detail/100
});


new Checkbox(panel, 10, 5, "draw bound",true,(x)=>{
	showRect=!showRect
	console.log('show rect:' + showRect)
	rect.style.display=showRect?'block':'none'
});
var tx=new TextArea(panel, 10, 80, "");
var lable=new Label(panel, 10, 65, "Status:");
window.addEventListener('init',(evt)=>{
      trace('init facedetect')
      trace(evt)
      tx.text+='\ninit-time:'+evt.detail+'ms'
    },{once:true})

function LoadCamera() {
    const promise = new Promise((resolve, reject) => {

      if (navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ video: true })
          .then(function (stream) {
            resolve(stream)
          })
          .catch(function (err0r) {
            reject('camera is not connected')
          });
      } else {
        reject('camera is not connected')
      }

    });
    return promise;
  }

function  setAABB(boundingBox) {



	  const x = boundingBox.topLeft[0];
      const y = boundingBox.topLeft[1];
      const h = boundingBox.bottomRight[1] - y;
      const w = boundingBox.bottomRight[0] - x;
      rect.style.left=x+'px'
      rect.style.width=w+'px'

      rect.style.top = y+'px';
       rect.style.height = h+'px';
    
	// body...
}
function pred(model,vid) {
	var time=Date.now();
	model.estimateFaces(vid).then(predicts=>{
		var delta=Date.now()-time;
		  window.dispatchEvent(new CustomEvent('init',{'detail': delta}))

		trace(predicts.length > 0)
		if(predicts.length > 0){
      const { annotations } = predicts[0];

      const lc = annotations['leftCheek'];
      const rc = annotations['rightCheek'];
      const deltax = lc[0][2] - rc[0][2];

      if (deltax > THRESHOLD) {
        lable.text="Status: LEFT"
      
        
      }else if(deltax <- THRESHOLD){
        lable.text="Status: RIGHT"
      }else{
        lable.text="Status: NONE"
      }

			 
			logs.textContent+=delta+'ms, '
			logs.scrollTop=logs.scrollHeight
			const boundingBox = predicts[0].boundingBox;
			setAABB(boundingBox);
		}
		
		setTimeout(x=>{
			 pred(model,vid)
		},requestDelay)
	})
	// body...
}
	var time=Date.now();
    loadModel().then(model => {
    	trace('model loaded')
    	var delta=Date.now()-time;

    	//trace(delta+'ms')
    	tx.text+='\nModel load time: '+delta+'ms';

    	 LoadCamera().then(stream => {
        trace('camera loaded');
        video.srcObject = stream;
        video.addEventListener('loadeddata', (evt)=>{
        	trace('video loaded')
        	 pred(model,video)
        })
       


    	})
    });




        }
      </script>
</body>
</html>
